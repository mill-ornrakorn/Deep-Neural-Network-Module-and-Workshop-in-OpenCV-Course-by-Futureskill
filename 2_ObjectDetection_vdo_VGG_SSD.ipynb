{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd5d2ff",
   "metadata": {},
   "source": [
    "# Object Detection กับ vdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8a8a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e415f",
   "metadata": {},
   "source": [
    "## ใช้ MobileNet_SSD และ VGG_SSD กับ vdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ffc8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(192, 156, 228), (168, 228, 60), (96, 228, 48), (168, 204, 192), (108, 108, 12), (132, 24, 132), (108, 132, 168), (12, 156, 144), (48, 120, 144), (12, 36, 12), (204, 216, 60), (96, 204, 144), (84, 24, 72), (192, 72, 228), (108, 36, 0), (144, 48, 48), (144, 204, 36), (0, 48, 192), (216, 72, 180), (156, 144, 60)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import helper # helper.py อันนี้อ.เขียนขึ้นมาเอง เพื่อช่วยการทำงานให้ง่ายขึ้น\n",
    "\n",
    "# --- Labels of Network. ---\n",
    "# ได้จากตอนโหลด model zoo มา คือ list ของ obj. ที่ model นี้สามารถ detect ได้ \n",
    "# โดย model ที่อาจารย์ยกตัวอย่างมาคือ mobilenet_SSD และ VGG_SSD มีการใช้ classNames ร่วมกัน จึงมีการ detect obj. ได้เท่ากัน\n",
    "classNames = { 0: 'background', # คือ ไม่เจออะไรเลย\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }\n",
    "\n",
    "\n",
    "# จากไฟล์ helper.py \n",
    "classColors = helper.getRandomColors(20) # สร้างสีมา 20 เพราะมี classNames อยู่ 20 ตัว โดย 20 สีนี้จะ random สีมาไม่ให้ซ้ำกัน\n",
    "print(classColors)\n",
    "\n",
    "\n",
    "# เตรียม vdo ที่ใช้\n",
    "cap = cv2.VideoCapture(\"road3.mp4\")\n",
    "\n",
    "\n",
    "# --- Load the Caffe model ---\n",
    "# สร้างมาจากแพลตฟอร์ม Caffe\n",
    "# parameter ตัวแรก: คือ จะเป็นตัวบอกข้อมูลข้างในของ network ว่ามีอะไรบ้าง\n",
    "# parameter ตัวที่สอง: คือ weight ของ model ว่า train มาอย่างไร\n",
    "#net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy.caffemodel\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"vgg_ssd.prototxt\", \"vgg_ssd.caffemodel\")\n",
    "\n",
    "# set Backend และ set Target ตาม pipeline โดยจะใช้ GPU ช่วยคำนวนจะได้ไว เพราะ vgg_ssd มีตัว weight ที่ใหญ่ และการคำนวนซับซ้อน(กว่า MobileNetSSD) \n",
    "# แต่ถ้าคอมใครไม่มี GPU ให้ comment 2 บรรทัดด้านล่างนี้ไป\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # MobileNet requires fixed dimensions for input image(s)\n",
    "    # convert เป็น blob file\n",
    "    #blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5), False) # บรรทัดนี้ใช้กับ MobileNetSSD\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 117, 123), False) # บรรทัดนี้ใช้กับ vgg_ssd\n",
    "\n",
    "    #Set to network the input blob เอา blob มาใส่เป็น input\n",
    "    net.setInput(blob)\n",
    "\n",
    "    #Prediction of network\n",
    "    # สั่งให้คำนวน จะได้เป็น list obj. ที่หาเจอ\n",
    "    detections = net.forward()\n",
    "\n",
    "    #Size of frame resize (300x300)\n",
    "    # Size of frame\n",
    "    # เก็บค่าของ height และ width ของรูปเดิมไว้ก่อน เพื่อจะได้คูณกลับเป็นรูปเดิมตอนถูกย่อขนาดรูปแล้ว\n",
    "    height = frame.shape[0]  \n",
    "    width = frame.shape[1] \n",
    "\n",
    "    # Locate location and class of object detected\n",
    "    # There is a fix index for class, location and confidence\n",
    "    # loop เข้าไปใน list ของ detections ที่เกิดขึ้น ว่าในนั้นมีกี่ตัว และแต่ละตัวเป็นตำแหน่งไหนบ้าง\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "        # ตัว detections จะมีรูปแบบมิติของ matrix อยู่ประมาณนี้ [0, 0, i, 2] โดย index ที่ 1, 2 จะเป็น dimention ว่าง หรือ 1 \n",
    "        # ซึ่งเราสนใจที่ index 3, 4 \n",
    "            # โดย index ที่ 3 คือ ลำดับของ obj. ที่เราเจอว่าเป็นตัวที่เท่าไร เช่น ตัวที่ 1 ในรูป ตัวที่ 2 ในรูป \n",
    "            # index ที่ 4 ช่องที่ 2 คือ ค่า confidence เป็นค่าความมั่นใจว่า obj. ที่เจอเป็นชนิดนีกี่ % \n",
    "        \n",
    "        if confidence > 0.3: # Filter prediction \n",
    "            class_id = int(detections[0, 0, i, 1]) # Class label # index ที่ 4 ช่องที่ 1 คือ class_id ว่าคือชนิดใด\n",
    "            \n",
    "            # Scale detection frame ที่จะเอามาวาดกรอบบนรูป\n",
    "            # โดยเอาค่าขนาดรูปเดิมมาคูณกับค่าที่ได้ เพราะค่าที่ได้ถูก normalize จนเหลือ 0 กับ 1 เท่านั้น พอเอามาคุณกับค่าเดิมของมันก็จะได้ขนาดรูปเดิมมาที่ตำแหน่งเดิม\n",
    "            xLeftBottom = int(width * detections[0, 0, i, 3]) # index ที่ 4 ช่องที่ 3 คือ จุด xLeftBottom\n",
    "            yLeftBottom = int(height * detections[0, 0, i, 4]) # index ที่ 4 ช่องที่ 4 คือ จุด yLeftBottom\n",
    "            xRightTop   = int(width * detections[0, 0, i, 5]) # index ที่ 4 ช่องที่ 5 คือ จุด xRightTop\n",
    "            yRightTop   = int(height * detections[0, 0, i, 6]) # index ที่ 4 ช่องที่ 6 คือ จุด yRightTop\n",
    "\n",
    "            # Draw location เอามาวาดกรอบสี่เหลี่ยมทับตำแหน่งนั้นเลย เพื่อดูว่ามัน detect เจอจริง ๆ มั้ย โดยใช้ค่าสีของ obj นั้น ๆ \n",
    "            cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),classColors[class_id])\n",
    "\n",
    "            # Draw label and confidence\n",
    "            label = classNames[class_id] + \": \" + str(confidence) # เอาค่า class_id (ชื่อชนิด)กับค่า confidence\n",
    "            # พิมพ์ตัวอักษรใส่เข้าไปในรูป\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "            yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "            # วาดสี่เหลี่ยมทับ และไฮไลท์พื้นหลังของตัวอักษรเป็นสีขาวจะได้เห็นชัด ๆ \n",
    "            cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),\n",
    "                                    (xLeftBottom + labelSize[0], yLeftBottom + baseLine),\n",
    "                                    (255, 255, 255), cv2.FILLED)\n",
    "            #วาด class_id (ชื่อชนิด)กับค่า confidence\n",
    "            cv2.putText(frame, label, (xLeftBottom, yLeftBottom),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) >= 0:  # Break with ESC \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd96a4",
   "metadata": {},
   "source": [
    "เมื่อ run เสร็จแล้วจะได้หน้าต่างด้านล่างขึ้นมา โดยจะแสดง obj. และค่า confidence เป็น frame by frame นั้น ๆ ออกมา"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877a908",
   "metadata": {},
   "source": [
    "![alt text](result_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f8061",
   "metadata": {},
   "source": [
    "พอลองใช้ทั้งสอง model แล้ว พบว่าทั้งสอง model มีความแม่นยำมาก สามารถตรวจจับได้ทั้งรถ รถจักรยานยนต์ และคนที่ขี่รถจักรยานยนต์ด้วย ที่ model สามารถตรวจจับได้แม่นยำเป็นเพราะทั้งสอง modelมีประสิทธิภาพ และข้อมูลที่เราใส่ไปสามารถมองเห็นแต่ละ obj ได้ชัดเจน"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bbd0a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
