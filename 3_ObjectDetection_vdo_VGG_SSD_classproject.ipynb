{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd5d2ff",
   "metadata": {},
   "source": [
    "# Object Detection กับ vdo “ตรวจจับรถยนต์ที่วิ่งเข้ามาในกรอบ”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8a8a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e415f",
   "metadata": {},
   "source": [
    "## ใช้ MobileNet_SSD และ VGG_SSD กับ vdo โดยกำหนด ROI เพื่อตรวจจับรถยนต์ที่วิ่งเข้ามาในกรอบ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ffc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "# --- Labels of Network. ---\n",
    "# ได้จากตอนโหลด model zoo มา คือ list ของ obj. ที่ model นี้สามารถ detect ได้ \n",
    "# โดย model ที่อาจารย์ยกตัวอย่างมาคือ mobilenet_SSD และ VGG_SSD มีการใช้ classNames ร่วมกัน จึงมีการ detect obj. ได้เท่ากัน\n",
    "classNames = { 0: 'background', # คือ ไม่เจออะไรเลย\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }\n",
    "\n",
    "# เตรียม vdo ที่ใช้\n",
    "cap = cv2.VideoCapture(\"road2.mp4\")\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('class_project_result.mp4', fourcc, 30.0, (640,  360))\n",
    "\n",
    "# --- Load the Caffe model ---\n",
    "# สร้างมาจากแพลตฟอร์ม Caffe\n",
    "# parameter ตัวแรก: คือ จะเป็นตัวบอกข้อมูลข้างในของ network ว่ามีอะไรบ้าง\n",
    "# parameter ตัวที่สอง: คือ weight ของ model ว่า train มาอย่างไร\n",
    "#net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy.caffemodel\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"vgg_ssd.prototxt\", \"vgg_ssd.caffemodel\")\n",
    "\n",
    "# set Backend และ set Target ตาม pipeline โดยจะใช้ GPU ช่วยคำนวนจะได้ไว เพราะ vgg_ssd มีตัว weight ที่ใหญ่ และการคำนวนซับซ้อน(กว่า MobileNetSSD) \n",
    "# แต่ถ้าคอมใครไม่มี GPU ให้ comment 2 บรรทัดด้านล่างนี้ไป\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "while True:\n",
    "    # Capture current frame\n",
    "    ret, vdo_frame = cap.read()\n",
    "\n",
    "    # Crop only the region of interest\n",
    "    roi_frame = vdo_frame[180:360,90:540]\n",
    "\n",
    "    # Apply median blur to remove high fequency noise (image gain noise).\n",
    "    frame = cv2.medianBlur(roi_frame, 3)\n",
    "\n",
    "    # MobileNet requires fixed dimensions for input image(s)\n",
    "    # convert เป็น blob file\n",
    "    #blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5), False) # บรรทัดนี้ใช้กับ MobileNetSSD\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 117, 123), False)\n",
    "    \n",
    "\n",
    "    #Set to network the input blob เอา blob มาใส่เป็น input\n",
    "    net.setInput(blob)\n",
    "\n",
    "    #Prediction of network\n",
    "    detections = net.forward()\n",
    "\n",
    "    #Size of frame resize (300x300)\n",
    "    # Size of frame \n",
    "    # เก็บค่าของ height และ width ของรูปเดิมไว้ก่อน เพื่อจะได้คูณกลับเป็นรูปเดิมตอนถูกย่อขนาดรูปแล้ว\n",
    "    height = frame.shape[0]  \n",
    "    width = frame.shape[1] \n",
    "\n",
    "    # Locate location and class of object detected\n",
    "    # There is a fix index for class, location and confidence\n",
    "    # loop เข้าไปใน list ของ detections ที่เกิดขึ้น ว่าในนั้นมีกี่ตัว และแต่ละตัวเป็นตำแหน่งไหนบ้าง\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "        # ตัว detections จะมีรูปแบบมิติของ matrix อยู่ประมาณนี้ [0, 0, i, 2] โดย index ที่ 1, 2 จะเป็น dimention ว่าง หรือ 1 \n",
    "        # ซึ่งเราสนใจที่ index 3, 4 \n",
    "            # โดย index ที่ 3 คือ ลำดับของ obj. ที่เราเจอว่าเป็นตัวที่เท่าไร เช่น ตัวที่ 1 ในรูป ตัวที่ 2 ในรูป \n",
    "            # index ที่ 4 ช่องที่ 2 คือ ค่า confidence เป็นค่าความมั่นใจว่า obj. ที่เจอเป็นชนิดนีกี่ % \n",
    "            \n",
    "        if (confidence > 0.50): # Filter prediction \n",
    "            class_id = int(detections[0, 0, i, 1]) # Class label # index ที่ 4 ช่องที่ 1 คือ class_id ว่าคือชนิดใด\n",
    "            \n",
    "            # Detect only car or bus\n",
    "            if((class_id==6)or(class_id==7)):\n",
    "                # Scale detection frame ที่จะเอามาวาดกรอบบนรูป\n",
    "                # โดยเอาค่าขนาดรูปเดิมมาคูณกับค่าที่ได้ เพราะค่าที่ได้ถูก normalize จนเหลือ 0 กับ 1 เท่านั้น พอเอามาคุณกับค่าเดิมของมันก็จะได้ขนาดรูปเดิมมาที่ตำแหน่งเดิม\n",
    "                xLeftBottom = int(width * detections[0, 0, i, 3]) # index ที่ 4 ช่องที่ 3 คือ จุด xLeftBottom\n",
    "                yLeftBottom = int(height * detections[0, 0, i, 4]) # index ที่ 4 ช่องที่ 4 คือ จุด yLeftBottom\n",
    "                xRightTop   = int(width * detections[0, 0, i, 5]) # index ที่ 4 ช่องที่ 5 คือ จุด xRightTop\n",
    "                yRightTop   = int(height * detections[0, 0, i, 6]) # index ที่ 4 ช่องที่ 6 คือ จุด yRightTop\n",
    "                \n",
    "                # Draw location เอามาวาดกรอบสี่เหลี่ยมทับตำแหน่งนั้นเลย เพื่อดูว่ามัน detect เจอจริง ๆ มั้ย \n",
    "                cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),(0,255,0),2)\n",
    "\n",
    "                # Draw label\n",
    "                label = classNames[class_id]\n",
    "                # พิมพ์ตัวอักษรใส่เข้าไปในรูป\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "                # วาดสี่เหลี่ยมทับ และไฮไลท์พื้นหลังของตัวอักษรเป็นสีขาวจะได้เห็นชัด ๆ \n",
    "                cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),(xLeftBottom + labelSize[0], yLeftBottom),(0,255,0), cv2.FILLED)\n",
    "                # วาด class_id (ชื่อชนิด)\n",
    "                cv2.putText(frame, label, (xLeftBottom, yLeftBottom),cv2.FONT_HERSHEY_PLAIN, 1.0, (0, 0, 0))\n",
    "\n",
    "    # Apply ROI back to VDO frame\n",
    "    vdo_frame[180:360,90:540] = frame\n",
    "\n",
    "    # Hilight region of interest in the VDO frame\n",
    "    cv2.rectangle(vdo_frame,(90,180),(540,360),(0,0,255),2)\n",
    "\n",
    "    # Write final result frame to file \n",
    "    out.write(vdo_frame)\n",
    "\n",
    "    cv2.imshow(\"result\", vdo_frame)\n",
    "    if cv2.waitKey(1) >= 0:  # Break with ESC \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fab8b3",
   "metadata": {},
   "source": [
    "เมื่อ run เสร็จแล้วจะได้หน้าต่างด้านล่างขึ้นมา โดยจะแสดง 'bus' หรือ 'car' ที่อยู่ในกรอบนั้นเป็น frame by frame ออกมาเท่านั้น"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b05a8",
   "metadata": {},
   "source": [
    "![alt text](result_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867614b3",
   "metadata": {},
   "source": [
    "พอลองใช้ทั้งสอง model แล้ว พบว่าทั้งสอง model มีความแม่นยำมาก สามารถตรวจจับได้ทั้งรถ รถจักรยานยนต์ และคนที่ขี่รถจักรยานยนต์ด้วย แต่ยังตรวจผิดอยู่บ้าง เช่น ตรวจรถบัสเป็นรถ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bbd0a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
